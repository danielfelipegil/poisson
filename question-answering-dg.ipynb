{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0. Exploratory analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "import pickle\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "df_devel=pd.read_json('project_files/devel.json')\n",
    "df_docs=pd.read_json('project_files/documents.json')\n",
    "df_testing=pd.read_json('project_files/testing.json')\n",
    "\n",
    "df_training=pd.read_pickle('project_files/df_training.pkl')\n",
    "\n",
    "\n",
    "question_learning_dataset = df_training[df_training.answer_type.notnull()]\n",
    "\n",
    "NER_corpus=load_obj('ner_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer,PunktTrainer\n",
    "\n",
    "tokenizer = load_obj('punk_tokenizer')\n",
    "tokenizer._params.abbrev_types.add('ii')\n",
    "tokenizer._params.abbrev_types.add('dr')\n",
    "\n",
    "questionwords = set([\"who\", \"what\", \"where\", \"when\", \"why\", \"how\", \"whose\", \"which\", \"whom\",\"whats\",\"what's\",\"whos\"])\n",
    "passiveQuestions = set([\"can\", \"could\", \"would\", \n",
    "                   \"was\", \"were\",\"am\",\"is\", \"are\", \"will\",\"shall\",\n",
    "                   \"did\",\"do\",\"does\",\n",
    "                   \"had\", \"have\",\"has\",\n",
    "                   \"as\",\"that\",\"in\",\n",
    "                   \"give an example\",\"name\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find Keywords\n",
    "2. Answer types - Using answer type taxonomy\n",
    "3. Query formulation -> Keywords\n",
    "4. Go to each document and check the frequency distribution of words and pick the document if one of the query words are present in document. Create a rank with that score\n",
    "5. Find the paragraphs -> Discard irrelevant paragraphs. Use NE,Keywords, longest exact keywords. Put same weight for now and calculate the score of paragraphs. Rank each of the paragraphs in the document. We have to use the original answer and match the answer type\n",
    "6. Find candidate answers -> Use supervised ML method\n",
    "7. Merge candidate answers -> Use NER\n",
    "8. Pick the best answer -> Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Question processing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring Stanford CoreNLP . Link -> https://blog.manash.me/configuring-stanford-parser-and-stanford-ner-tagger-with-nltk-in-python-on-windows-f685483c374a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.tag.stanford import CoreNLPNERTagger\n",
    "from itertools import groupby\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) \n",
    "\n",
    "\n",
    "def get_Name_Entity_NLTK(data):\n",
    "    results=[]\n",
    "    for sentence in data:\n",
    "        ne_chunked_sents = ne_chunk(pos_tag(word_tokenize(sentence)))\n",
    "        result = []\n",
    "\n",
    "        for tagged_tree in ne_chunked_sents:\n",
    "\n",
    "            if hasattr(tagged_tree, 'label'):\n",
    "                entity_name = ' '.join(c[0] for c in tagged_tree.leaves()) #\n",
    "                entity_type = tagged_tree.label() # get NE category\n",
    "                result.append((entity_name, entity_type))\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_Name_Entity_Sentence(sentence):\n",
    "    st = CoreNLPNERTagger(url='http://localhost:9000')\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    classified_text = st.tag(tokenized_text)\n",
    "    result = []\n",
    "    \n",
    "    for tag, chunk in groupby(classified_text, lambda x:x[1]):\n",
    "       if tag != \"O\":\n",
    "            word = \" \".join(w for w, t in chunk)\n",
    "            result.append((word.lower(), tag))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def addNameEntity(df,feature,func):\n",
    "    if 'NE'+\"_\"+feature in df:\n",
    "        df = df.drop('NE'+\"_\"+feature, axis=1)\n",
    "    df[\"NE\"+\"_\"+feature] = func(df[feature])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_type(question):\n",
    "    found  = False\n",
    "    result = 'other'\n",
    "    question_tokens = nltk.word_tokenize(question)\n",
    "    for token in question_tokens:\n",
    "        if token in questionwords:\n",
    "            found = True\n",
    "            result = token\n",
    "    if not found:\n",
    "        for token in question_tokens:\n",
    "            if token in passiveQuestions:\n",
    "                found = True\n",
    "                result = token\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "POS = set([\"NN\",\"NNS\",\"NNP\",\"NNPS\",\"CD\",\"JJ\",\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\"]) \n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) \n",
    "\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,wn.NOUN)\n",
    "    if (lemma == word):\n",
    "        lemma = lemmatizer.lemmatize(word,wn.VERB)\n",
    "        \n",
    "    return lemma\n",
    "\n",
    "def get_keyword(data):\n",
    "    result = []\n",
    "    sentence=data\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokenized_text)\n",
    "    for text,pos in tagged:\n",
    "        text = lemmatize(text.lower())\n",
    "        if text not in stopwords:\n",
    "            if pos in POS:\n",
    "                result.append(text)\n",
    "                \n",
    "    return result\n",
    "\n",
    "def get_keyword_paragraph(data):\n",
    "    results=[]\n",
    "    tokenized_sentence = tokenizer.tokenize(data)\n",
    "    for sentence in tokenized_sentence:\n",
    "        result = get_keyword(sentence)\n",
    "        results.append(result)\n",
    "        \n",
    "    return results\n",
    "\n",
    "def get_keyword_all(data):\n",
    "    results=[]\n",
    "    for sentence in data:\n",
    "        result = get_keyword(sentence)\n",
    "        results.append(result)\n",
    "        \n",
    "    return results\n",
    "\n",
    "def add_keywords(df,feature):\n",
    "    if 'keywords'+\"_\"+feature in df:\n",
    "        df = df.drop('keywords'+\"_\"+feature, axis=1)\n",
    "    df['keywords'+\"_\"+feature]=get_keyword_all(df[feature])\n",
    "    return df\n",
    "\n",
    "def get_number_of_common_kewyords(question_keywords,answer_sentence_keywords):\n",
    "    sum_keywords=0\n",
    "    for qkey in question_keywords:\n",
    "        if qkey in answer_sentence_keywords:\n",
    "            sum_keywords+=1\n",
    "    \n",
    "    return sum_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train a classifier</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW extraction for passages and questions\n",
    "def get_passages_bow(passages):\n",
    "    passage_bow={}\n",
    "    for passage in passages:\n",
    "        for token in nltk.word_tokenize(passage):\n",
    "            if token not in stopwords: \n",
    "                word=lemmatize(token.lower())\n",
    "                passage_bow[word] = passage_bow.get(word, 0) +  1\n",
    "    \n",
    "    return passage_bow\n",
    "\n",
    "def get_sentences_bow(sentences):\n",
    "    sentence_bow={}\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for token in nltk.word_tokenize(sentence):\n",
    "            if token not in stopwords:\n",
    "                word=lemmatize(token.lower())\n",
    "                sentence_bow[word] = sentence_bow.get(word, 0) +  1\n",
    "    \n",
    "    return sentence_bow\n",
    "\n",
    "def get_question_bow(question):\n",
    "    question_bow={}\n",
    "    question_bow[get_question_type(question)]=1\n",
    "    for token in nltk.word_tokenize(question):\n",
    "        if token not in stopwords: \n",
    "            word=lemmatize(token.lower())\n",
    "            question_bow[word] = question_bow.get(word, 0) +  1\n",
    "                \n",
    "    return question_bow\n",
    "\n",
    "def get_training_question_bow(question,keywords,qt):\n",
    "    question_bow={}\n",
    "    question_bow[qt]=1\n",
    "    for token in nltk.word_tokenize(question):\n",
    "        if token not in stopwords: \n",
    "            word=lemmatize(token.lower())\n",
    "            if word in keywords:\n",
    "                question_bow[word] = question_bow.get(word, 0) +  1\n",
    "                \n",
    "    return question_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_questions(questions, keywords,qt):\n",
    "    qs = []\n",
    "    for i,question in enumerate(questions):\n",
    "        q_bow = get_training_question_bow(question,keywords,qt[i])\n",
    "        qs.append(q_bow)\n",
    "        \n",
    "    return qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def check_results(predictions, classifications):\n",
    "    print(\"Accuracy:\")\n",
    "    print(accuracy_score(classifications,predictions))\n",
    "    print(classification_report(classifications,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "    \n",
    "# get the most common words from answer sentences (we can twek this for paragraph)\n",
    "answer_sentences_bow=get_sentences_bow(question_learning_dataset[question_learning_dataset['answer_found'].notnull()]['answer_found'])\n",
    "answer_keywords = set([word for word, count in answer_sentences_bow.items()])\n",
    "\n",
    "#qs_training=get_feature_questions(questions,answer_keywords)\n",
    "qs_training=get_feature_questions(list(question_learning_dataset.question),answer_keywords,list(question_learning_dataset.question_type))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.8369626130814186\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   CAUSE_OF_DEATH       1.00      0.47      0.64       327\n",
      "             CITY       1.00      0.08      0.15        12\n",
      "          COUNTRY       0.94      0.54      0.69      1058\n",
      "  CRIMINAL_CHARGE       1.00      0.33      0.49        64\n",
      "             DATE       0.76      0.99      0.86      5801\n",
      "         DURATION       0.96      0.64      0.77       464\n",
      "         IDEOLOGY       1.00      0.56      0.71       232\n",
      "         LOCATION       0.79      0.91      0.85      1738\n",
      "             MISC       1.00      0.50      0.67       133\n",
      "            MONEY       1.00      0.83      0.91       462\n",
      "      NATIONALITY       0.99      0.44      0.61       858\n",
      "           NUMBER       0.93      0.91      0.92      4644\n",
      "          ORDINAL       1.00      0.65      0.79       406\n",
      "     ORGANIZATION       1.00      0.51      0.68       496\n",
      "          PERCENT       0.98      0.85      0.91       751\n",
      "           PERSON       0.79      0.98      0.87      5468\n",
      "         RELIGION       0.99      0.62      0.76       493\n",
      "              SET       1.00      0.39      0.56       174\n",
      "STATE_OR_PROVINCE       1.00      0.43      0.60       335\n",
      "             TIME       1.00      0.42      0.59        53\n",
      "            TITLE       1.00      0.34      0.50      1000\n",
      "              URL       1.00      0.54      0.70        13\n",
      "\n",
      "      avg / total       0.87      0.84      0.82     24982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "if (len(qs_training)>0 and len(list(question_learning_dataset.question_type))>0):\n",
    "    # fit vectorizer\n",
    "    vectorizer = DictVectorizer()\n",
    "    \n",
    "    X_train_dtm = vectorizer.fit_transform(qs_training)\n",
    "    \n",
    "    \n",
    "\n",
    "    model=RandomForestClassifier(n_estimators = 300, max_depth = 60, criterion = 'entropy')\n",
    "    \n",
    "    # tag the answers\n",
    "    # fit a logistic regression model to the data \n",
    "    # build classifier\n",
    "    #model = MultinomialNB(2, False, None)\n",
    "\n",
    "    # train the model using X_train_dtm \n",
    "    model.fit(X_train_dtm, list(question_learning_dataset.answer_type))\n",
    "    \n",
    "    y_predicted_class = model.predict(X_train_dtm)\n",
    "    \n",
    "    check_results(y_predicted_class,list(question_learning_dataset.answer_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Candidate answering generation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Get a score for the passage to filter the most relevant passages</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## features relevant to this part\n",
    "# number of named entities of the right type in the passage\n",
    "# number of question keywords in the passage\n",
    "# the longest exact sequence of question keywords\n",
    "# rank of the document where the passage was extracted\n",
    "# proximity of the keywords from the original query\n",
    "# ngram overlap between the passage and the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will set up useful functions to extract term frequencies to build the vector space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) # wrap in a set() (see below)\n",
    "\n",
    "\n",
    "# get the terms for a passage\n",
    "def get_terms(passage):\n",
    "    terms = set()\n",
    "    for token in nltk.word_tokenize(passage):\n",
    "        if token not in stopwords: \n",
    "            terms.add(lemmatize(token.lower()))\n",
    "    return terms\n",
    "    \n",
    "# get document_term \n",
    "def get_document_term_passsages(ds_documents):\n",
    "    document_term={}\n",
    "    passageID=0\n",
    "    for index, row in ds_documents.iterrows():\n",
    "        passageID=0\n",
    "        terms={}\n",
    "        # every row is a document\n",
    "        list_of_passages=row['text']\n",
    "        for passage in list_of_passages:\n",
    "            terms[passageID]=get_terms(passage)\n",
    "            passageID+=1\n",
    "            \n",
    "        document_term[row['docid']]=terms\n",
    "    return document_term\n",
    "\n",
    "# get the term frequency\n",
    "def extract_term_freqs(doc):\n",
    "    tfs = Counter()\n",
    "    for token in doc:\n",
    "        if token not in stopwords: \n",
    "            tfs[lemmatize(token.lower())] += 1\n",
    "    return tfs\n",
    "        \n",
    "# compute idf\n",
    "def compute_doc_freqs(doc_term_freqs):\n",
    "    doc_dic = {}\n",
    "    for key, value in doc_term_freqs.items():\n",
    "        dfs = Counter()\n",
    "        for passage_id,tfs in value.items():\n",
    "            for term in tfs.keys():\n",
    "                dfs[term] += 1\n",
    "        doc_dic[key] = dfs\n",
    "        \n",
    "    return doc_dic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a document-term matrix\n",
    "docs=get_document_term_passsages(df_docs)\n",
    "#docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector space model we need to define a score function\n",
    "# first I will use tf-idf\n",
    "doc_term_freqs = {}\n",
    "for docid,dic_passages in docs.items():\n",
    "    passage_dic = {}\n",
    "    for passage_id, terms in dic_passages.items():\n",
    "        term_freqs = extract_term_freqs(terms)\n",
    "        passage_dic[passage_id] = term_freqs\n",
    "    doc_term_freqs[docid] = passage_dic\n",
    "\n",
    "doc_freqs = compute_doc_freqs(doc_term_freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_term_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Improvement:</b> Use BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an inverted index for query processing. Inverted index will not change from query to query. Here we can improve how the weight is defined for the posting list tuple for each term (docid,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(freqs):\n",
    "    p_count=0\n",
    "    for counter in freqs.values():\n",
    "        p_count+=sum(counter.values())\n",
    "    \n",
    "    #print(p_count)\n",
    "    return p_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from WSTA_N16_information_retrieval\n",
    "vsm_inverted_index_all = defaultdict()\n",
    "for docid, passage_freqs in doc_term_freqs.items():\n",
    "    vsm_inverted_index = defaultdict(list)\n",
    "    \n",
    "    #N = sum(passage_freqs.values())\n",
    "    N = count_words(passage_freqs)\n",
    "    #print(N,passage_freqs)\n",
    "    for passage_id, term_freqs in passage_freqs.items():\n",
    "        length = 0\n",
    "        # find tf*idf values and accumulate sum of squares \n",
    "        tfidf_values = []\n",
    "        M = len(passage_freqs)\n",
    "        for term, count in term_freqs.items():\n",
    "            tfidf = float(count) / N * log(M / float(doc_freqs[docid][term])) # should be number of documents (paragraphs) with term\n",
    "            tfidf_values.append((term, tfidf))\n",
    "            length += tfidf ** 2\n",
    "\n",
    "        # normalise documents by length and insert into index\n",
    "        length = length ** 0.5\n",
    "        for term, tfidf in tfidf_values:\n",
    "            # note the inversion of the indexing, to be term -> (doc_id, score)\n",
    "            vsm_inverted_index[term].append([passage_id, tfidf / length])\n",
    "    vsm_inverted_index_all[docid] = vsm_inverted_index\n",
    "\n",
    "# ensure posting lists are in sorted order (less important here cf above)\n",
    "for key, value in vsm_inverted_index_all.items():\n",
    "    for term, docids in value.items():\n",
    "        docids.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsm_inverted_index_all=load_obj('vsm_inverted_index_corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the VSM creating a score for each document (passage) and returning the top k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# get a list of paragraphs ordered by relevance on the question\n",
    "def query_vsm(query, index):\n",
    "    accumulator = Counter()\n",
    "    for term in query:\n",
    "        postings = index[term]\n",
    "        for docid, weight in postings:\n",
    "            accumulator[docid] += weight\n",
    "    return accumulator\n",
    "\n",
    "## end copied code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Candidate answering scoring</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'June 16, 1911'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def correct_answer(predicted,predicted_answer_sentence):\n",
    "\n",
    "    tokens=nltk.word_tokenize(predicted)\n",
    "    pattern='.*('\n",
    "    for token in  tokens:\n",
    "        pattern=pattern+token+'\\s*'\n",
    "    pattern=pattern+').*'\n",
    "\n",
    "    reg=re.compile(pattern,re.IGNORECASE)\n",
    "    if len(re.findall(reg,predicted_answer_sentence)):\n",
    "        predicted=re.findall(reg,predicted_answer_sentence)[0].strip()\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "def isAnswerInSentence(answer,answer_sentence):\n",
    "\n",
    "    tokens=nltk.word_tokenize(answer)\n",
    "    pattern='.*('\n",
    "    for token in  tokens:\n",
    "        pattern=pattern+token+'\\s*'\n",
    "    pattern=pattern+').*'\n",
    "\n",
    "    reg=re.compile(pattern,re.IGNORECASE)\n",
    "    if len(re.findall(reg,answer_sentence)):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_devel=load_obj('df_devel_predicted_answer_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "df_devel=load_obj('df_devel_predicted_answer_type')\n",
    "#df_devel=pd.read_json('project_files/devel.json')\n",
    "df_result_devel=pd.DataFrame(columns=['id','question','paragraph','retrieved paras','predicted_paragraph','paragraph_found','sentence','predicted_sentence','answer','predicted_answer'])\n",
    "df_devel=df_devel.iloc[0:20]\n",
    "\n",
    "for index, row in df_devel.iterrows():\n",
    "    t=time.process_time()\n",
    "    question=row['question']\n",
    "    docid=row['docid']\n",
    "    ida=index\n",
    "    \n",
    "    \n",
    "    question_keywords=get_keyword(question)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get the most relevant documents for the question\n",
    "    results = query_vsm(question_keywords, vsm_inverted_index_all[docid])\n",
    "    documents_ranked=results.most_common(10) \n",
    "    \n",
    "    \n",
    "    # prediction --not necessary if loading from pickle\n",
    "    #q_bow=get_question_bow(question)\n",
    "    #x = vectorizer.transform(q_bow)\n",
    "    #answer_type=model.predict(x)\n",
    "    answer_type=row['predicted_answer_type']\n",
    "    \n",
    "    passages_dict={}\n",
    "    sentences_dict={}\n",
    "    score_dict={}\n",
    "    answer=''\n",
    "    df_best_sentences=pd.DataFrame(columns=['doc_id','para_id','sentence_id','sentence_text','score'])\n",
    "    if len(documents_ranked)>0:\n",
    "        \n",
    "        for document in documents_ranked:\n",
    "            # perform a paragraph segmentation\n",
    "            paragraph_id=document[0]\n",
    "            paragraph_text=df_docs.iloc[docid]['text'][paragraph_id]\n",
    "            sentences_dict[paragraph_id]=tokenizer.tokenize(paragraph_text)\n",
    "        \n",
    "        score=0\n",
    "        for paragraph_dict in sentences_dict.items():\n",
    "            paragraph_id=paragraph_dict[0]\n",
    "            sentences_list=paragraph_dict[1]\n",
    "            \n",
    "            for sentence_index in range(len(sentences_list)):\n",
    "                NER_sentence=NER_corpus[docid][paragraph_id][sentence_index]\n",
    "                common_keywords=get_number_of_common_kewyords(question_keywords,get_keyword(sentences_list[sentence_index]))\n",
    "                similarity=nlp(question).similarity(nlp(sentences_list[sentence_index]))\n",
    "                score=common_keywords+similarity\n",
    "            \n",
    "                for entity in NER_sentence:\n",
    "                    if (entity[1]==answer_type):\n",
    "                        score+=1\n",
    "                        break\n",
    "                        \n",
    "                df_best_sentences.loc[len(df_best_sentences)]=[docid,paragraph_id,sentence_index,sentences_list[sentence_index],score]\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        if len(df_best_sentences)>0: # answer='' otherwise\n",
    "                   \n",
    "            best_paragraph_id=df_best_sentences.loc[df_best_sentences.score.idxmax()]['para_id']\n",
    "            best_sentence_id=df_best_sentences.loc[df_best_sentences.score.idxmax()]['sentence_id']\n",
    "            best_sentence_text=df_best_sentences.loc[df_best_sentences.score.idxmax()]['sentence_text']\n",
    "            NER_answer_passage=NER_corpus[docid][best_paragraph_id][best_sentence_id]\n",
    "            for entity in NER_answer_passage:\n",
    "                if (entity[1]==answer_type):\n",
    "                    #print('answer:',entity[0])\n",
    "                    answer=correct_answer(entity[0],best_sentence_text)\n",
    "                    #print('corrected:',answer)\n",
    "                    break\n",
    "                    \n",
    "        \n",
    "    ## only for testing purposes - get the answer sentence and check the retrieved paragraph agains the selected\n",
    "    possible_par=[par[0] for par in documents_ranked]\n",
    "    par_retrieved=False\n",
    "    if row['answer_paragraph'] in possible_par:\n",
    "        par_retrieved=True\n",
    "        \n",
    "    sent_ans=''\n",
    "    \n",
    "    \n",
    "    for para in df_docs.iloc[docid]['text']:\n",
    "        sent_doc=tokenizer.tokenize(para)\n",
    "        #print(sent_doc)\n",
    "        for sent in sent_doc:\n",
    "            \n",
    "            if isAnswerInSentence(row['text'],sent):       \n",
    "                sent_ans=sent_doc\n",
    "                break\n",
    "    ## END -only for testing purposes\n",
    "    \n",
    "    print(ida,time.process_time()-t)\n",
    "    df_result_devel.loc[len(df_result_devel)]=[docid,question,row['answer_paragraph'],possible_par,best_paragraph_id,par_retrieved,sent_ans,best_sentence_text,row['text'],answer]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in paragraph found: 100.0 %\n",
      "Accuracy in sentence selected: 35.0 %\n",
      "Answer mismatch: 90.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy in paragraph found:',df_result_devel.loc[df_result_devel['paragraph_found']==True]['id'].count()/len(df_result_devel)*100,'%')\n",
    "print('Accuracy in sentence selected:',len(df_result_devel.loc[df_result_devel.paragraph!=df_result_devel.predicted_paragraph])/len(df_result_devel)*100,'%')\n",
    "print('Answer mismatch:',len(df_result_devel.loc[df_result_devel.predicted_answer!=df_result_devel.answer])/len(df_result_devel)*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>retrieved paras</th>\n",
       "      <th>predicted_paragraph</th>\n",
       "      <th>paragraph_found</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predicted_sentence</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380</td>\n",
       "      <td>On what date did the companies that became the...</td>\n",
       "      <td>5</td>\n",
       "      <td>[5, 0, 13, 8, 7, 6, 1, 10, 9, 15]</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>[On June 16, 1911, their four companies were c...</td>\n",
       "      <td>On June 16, 1911, their four companies were co...</td>\n",
       "      <td>june 16 , 1911</td>\n",
       "      <td>June 16, 1911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>380</td>\n",
       "      <td>What percentage of its desktop PCs does IBM pl...</td>\n",
       "      <td>22</td>\n",
       "      <td>[22, 16, 19, 7, 3, 9, 20, 0, 1, 2]</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "      <td>[IBM announced it will launch its new software...</td>\n",
       "      <td>IBM plans to install Open Client on 5% of its ...</td>\n",
       "      <td>5 %</td>\n",
       "      <td>5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>380</td>\n",
       "      <td>What year did IBM hire its first black salesman?</td>\n",
       "      <td>16</td>\n",
       "      <td>[16, 17, 18, 15, 6, 8, 10, 12, 7, 0]</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>[IBM was among the first corporations to provi...</td>\n",
       "      <td>In 1946, the company hired its first black sal...</td>\n",
       "      <td>1946</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380</td>\n",
       "      <td>IBM made an acquisition in 2009, name it.</td>\n",
       "      <td>4</td>\n",
       "      <td>[11, 10, 4, 6, 0, 17, 8, 5, 16, 22]</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>[In 2005, the company sold its personal comput...</td>\n",
       "      <td>IBM acquired Kenexa (2012) and SPSS (2009) and...</td>\n",
       "      <td>spss</td>\n",
       "      <td>Kenexa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>380</td>\n",
       "      <td>This IBM invention is known by the acronym UPC...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 17, 6, 0, 8, 5, 1, 3, 4, 7]</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>[IBM has 12 research laboratories worldwide, b...</td>\n",
       "      <td>The following year, IBM hosted its first Inven...</td>\n",
       "      <td>universal product code</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>380</td>\n",
       "      <td>In 2012 Fortune ranked the largest US firms by...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 13, 21, 15, 19, 16, 9, 4, 10, 18]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>[In 2012, Fortune ranked IBM the second larges...</td>\n",
       "      <td>In 2012, Fortune ranked IBM the second largest...</td>\n",
       "      <td>second largest</td>\n",
       "      <td>second</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380</td>\n",
       "      <td>How many gallons of liquid cleaning agent leak...</td>\n",
       "      <td>25</td>\n",
       "      <td>[25, 14, 0, 1, 2, 3, 4, 7, 8, 9]</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>[The birthplace of IBM, Endicott, suffered pol...</td>\n",
       "      <td>IBM used liquid cleaning agents in circuit boa...</td>\n",
       "      <td>4,100 gallons</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380</td>\n",
       "      <td>In what year did IBM get its name?</td>\n",
       "      <td>0</td>\n",
       "      <td>[17, 13, 8, 10, 0, 16, 6, 23, 5, 2]</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>[IBM's employee management practices can be tr...</td>\n",
       "      <td>The following year, IBM hosted its first Inven...</td>\n",
       "      <td>1924</td>\n",
       "      <td>The following year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>380</td>\n",
       "      <td>DeveloperWorks has content about open industry...</td>\n",
       "      <td>20</td>\n",
       "      <td>[20, 19, 22, 10, 4, 9, 2, 17, 21, 7]</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>[IBM announced it will launch its new software...</td>\n",
       "      <td>Subjects range from open, industry-standard te...</td>\n",
       "      <td>linux</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>What web browser does the Open Document Format...</td>\n",
       "      <td>22</td>\n",
       "      <td>[22, 20, 19, 7]</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "      <td>[IBM announced it will launch its new software...</td>\n",
       "      <td>One alternative to Microsoft's office document...</td>\n",
       "      <td>mozilla firefox</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>380</td>\n",
       "      <td>What is the name of the IBM project that redir...</td>\n",
       "      <td>23</td>\n",
       "      <td>[23, 17, 8, 13, 10, 9, 19, 0, 16, 6]</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>[In 2006, IBM launched Secure Blue, encryption...</td>\n",
       "      <td>A year later, IBM unveiled Project Big Green, ...</td>\n",
       "      <td>project big green</td>\n",
       "      <td>A year later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>380</td>\n",
       "      <td>IBM runs what website for software developers?</td>\n",
       "      <td>20</td>\n",
       "      <td>[20, 22, 19, 11, 10, 24, 9, 14, 0, 1]</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>[DeveloperWorks is a website run by IBM for so...</td>\n",
       "      <td>DeveloperWorks is a website run by IBM for sof...</td>\n",
       "      <td>developerworks</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>380</td>\n",
       "      <td>In what year did IBM add sexual orientation to...</td>\n",
       "      <td>18</td>\n",
       "      <td>[18, 17, 16, 10, 8, 23, 13, 2, 15, 12]</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>[On September 21, 1953, Thomas Watson, Jr., th...</td>\n",
       "      <td>In 1984, IBM added sexual orientation to its n...</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>380</td>\n",
       "      <td>What was the name of the company that eventual...</td>\n",
       "      <td>0</td>\n",
       "      <td>[8, 0, 6, 7, 5, 17, 1, 10, 9, 15]</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>In 1952, Thomas Watson, Sr., stepped down afte...</td>\n",
       "      <td>computing-tabulating-recording company ( ctr )</td>\n",
       "      <td>Thomas Watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>380</td>\n",
       "      <td>What location is the birthplace of IBM?</td>\n",
       "      <td>25</td>\n",
       "      <td>[25, 0, 1, 2, 3, 4, 7, 8, 9, 10]</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>[The birthplace of IBM, Endicott, suffered pol...</td>\n",
       "      <td>In 1956, the company demonstrated the first pr...</td>\n",
       "      <td>endicott</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>380</td>\n",
       "      <td>IBM expanded their nondiscrimination policy in...</td>\n",
       "      <td>18</td>\n",
       "      <td>[17, 18, 3, 6, 14, 11, 25, 7, 19, 13]</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>[On September 21, 1953, Thomas Watson, Jr., th...</td>\n",
       "      <td>In 1961, IBM's nondiscrimination policy was ex...</td>\n",
       "      <td>sexual orientation</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>380</td>\n",
       "      <td>IBM employees created a magazine in 1935, what...</td>\n",
       "      <td>16</td>\n",
       "      <td>[16, 15, 6, 5, 0, 9, 17, 8, 18, 2]</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>[IBM was among the first corporations to provi...</td>\n",
       "      <td>In 1935, the employee magazine Think was created.</td>\n",
       "      <td>think</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>380</td>\n",
       "      <td>Secure Blue was launched in what year?</td>\n",
       "      <td>23</td>\n",
       "      <td>[10, 23, 16, 17, 0, 15, 8, 22, 13, 2]</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>[In 2006, IBM launched Secure Blue, encryption...</td>\n",
       "      <td>A year later IBM launched Secure Blue, a low-c...</td>\n",
       "      <td>2006</td>\n",
       "      <td>A year later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>380</td>\n",
       "      <td>What will IBM use to analyze weather and make ...</td>\n",
       "      <td>11</td>\n",
       "      <td>[11, 22, 0, 16, 6, 9, 5, 23, 21, 25]</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>[On September 21, 1953, Thomas Watson, Jr., th...</td>\n",
       "      <td>The acquisition seeks to use Watson for weathe...</td>\n",
       "      <td>watson</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>380</td>\n",
       "      <td>Who created the IBM name?</td>\n",
       "      <td>0</td>\n",
       "      <td>[16, 15, 0, 17, 8, 5, 6, 1, 2, 3]</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>[In 1952, Thomas J. Watson, Jr., published the...</td>\n",
       "      <td>In 1956, the company demonstrated the first pr...</td>\n",
       "      <td>thomas j. watson</td>\n",
       "      <td>Arthur L. Samuel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           question paragraph  \\\n",
       "0   380  On what date did the companies that became the...         5   \n",
       "1   380  What percentage of its desktop PCs does IBM pl...        22   \n",
       "2   380   What year did IBM hire its first black salesman?        16   \n",
       "3   380          IBM made an acquisition in 2009, name it.         4   \n",
       "4   380  This IBM invention is known by the acronym UPC...         2   \n",
       "5   380  In 2012 Fortune ranked the largest US firms by...         1   \n",
       "6   380  How many gallons of liquid cleaning agent leak...        25   \n",
       "7   380                 In what year did IBM get its name?         0   \n",
       "8   380  DeveloperWorks has content about open industry...        20   \n",
       "9   380  What web browser does the Open Document Format...        22   \n",
       "10  380  What is the name of the IBM project that redir...        23   \n",
       "11  380     IBM runs what website for software developers?        20   \n",
       "12  380  In what year did IBM add sexual orientation to...        18   \n",
       "13  380  What was the name of the company that eventual...         0   \n",
       "14  380            What location is the birthplace of IBM?        25   \n",
       "15  380  IBM expanded their nondiscrimination policy in...        18   \n",
       "16  380  IBM employees created a magazine in 1935, what...        16   \n",
       "17  380             Secure Blue was launched in what year?        23   \n",
       "18  380  What will IBM use to analyze weather and make ...        11   \n",
       "19  380                          Who created the IBM name?         0   \n",
       "\n",
       "                           retrieved paras predicted_paragraph  \\\n",
       "0        [5, 0, 13, 8, 7, 6, 1, 10, 9, 15]                   5   \n",
       "1       [22, 16, 19, 7, 3, 9, 20, 0, 1, 2]                  22   \n",
       "2     [16, 17, 18, 15, 6, 8, 10, 12, 7, 0]                  16   \n",
       "3      [11, 10, 4, 6, 0, 17, 8, 5, 16, 22]                   4   \n",
       "4          [2, 17, 6, 0, 8, 5, 1, 3, 4, 7]                  17   \n",
       "5    [1, 13, 21, 15, 19, 16, 9, 4, 10, 18]                   1   \n",
       "6         [25, 14, 0, 1, 2, 3, 4, 7, 8, 9]                  25   \n",
       "7      [17, 13, 8, 10, 0, 16, 6, 23, 5, 2]                  17   \n",
       "8     [20, 19, 22, 10, 4, 9, 2, 17, 21, 7]                  20   \n",
       "9                          [22, 20, 19, 7]                  22   \n",
       "10    [23, 17, 8, 13, 10, 9, 19, 0, 16, 6]                  23   \n",
       "11   [20, 22, 19, 11, 10, 24, 9, 14, 0, 1]                  20   \n",
       "12  [18, 17, 16, 10, 8, 23, 13, 2, 15, 12]                  18   \n",
       "13       [8, 0, 6, 7, 5, 17, 1, 10, 9, 15]                   8   \n",
       "14        [25, 0, 1, 2, 3, 4, 7, 8, 9, 10]                   8   \n",
       "15   [17, 18, 3, 6, 14, 11, 25, 7, 19, 13]                  17   \n",
       "16      [16, 15, 6, 5, 0, 9, 17, 8, 18, 2]                  16   \n",
       "17   [10, 23, 16, 17, 0, 15, 8, 22, 13, 2]                  10   \n",
       "18    [11, 22, 0, 16, 6, 9, 5, 23, 21, 25]                  11   \n",
       "19       [16, 15, 0, 17, 8, 5, 6, 1, 2, 3]                   8   \n",
       "\n",
       "   paragraph_found                                           sentence  \\\n",
       "0             True  [On June 16, 1911, their four companies were c...   \n",
       "1             True  [IBM announced it will launch its new software...   \n",
       "2             True  [IBM was among the first corporations to provi...   \n",
       "3             True  [In 2005, the company sold its personal comput...   \n",
       "4             True  [IBM has 12 research laboratories worldwide, b...   \n",
       "5             True  [In 2012, Fortune ranked IBM the second larges...   \n",
       "6             True  [The birthplace of IBM, Endicott, suffered pol...   \n",
       "7             True  [IBM's employee management practices can be tr...   \n",
       "8             True  [IBM announced it will launch its new software...   \n",
       "9             True  [IBM announced it will launch its new software...   \n",
       "10            True  [In 2006, IBM launched Secure Blue, encryption...   \n",
       "11            True  [DeveloperWorks is a website run by IBM for so...   \n",
       "12            True  [On September 21, 1953, Thomas Watson, Jr., th...   \n",
       "13            True                                                      \n",
       "14            True  [The birthplace of IBM, Endicott, suffered pol...   \n",
       "15            True  [On September 21, 1953, Thomas Watson, Jr., th...   \n",
       "16            True  [IBM was among the first corporations to provi...   \n",
       "17            True  [In 2006, IBM launched Secure Blue, encryption...   \n",
       "18            True  [On September 21, 1953, Thomas Watson, Jr., th...   \n",
       "19            True  [In 1952, Thomas J. Watson, Jr., published the...   \n",
       "\n",
       "                                   predicted_sentence  \\\n",
       "0   On June 16, 1911, their four companies were co...   \n",
       "1   IBM plans to install Open Client on 5% of its ...   \n",
       "2   In 1946, the company hired its first black sal...   \n",
       "3   IBM acquired Kenexa (2012) and SPSS (2009) and...   \n",
       "4   The following year, IBM hosted its first Inven...   \n",
       "5   In 2012, Fortune ranked IBM the second largest...   \n",
       "6   IBM used liquid cleaning agents in circuit boa...   \n",
       "7   The following year, IBM hosted its first Inven...   \n",
       "8   Subjects range from open, industry-standard te...   \n",
       "9   One alternative to Microsoft's office document...   \n",
       "10  A year later, IBM unveiled Project Big Green, ...   \n",
       "11  DeveloperWorks is a website run by IBM for sof...   \n",
       "12  In 1984, IBM added sexual orientation to its n...   \n",
       "13  In 1952, Thomas Watson, Sr., stepped down afte...   \n",
       "14  In 1956, the company demonstrated the first pr...   \n",
       "15  In 1961, IBM's nondiscrimination policy was ex...   \n",
       "16  In 1935, the employee magazine Think was created.   \n",
       "17  A year later IBM launched Secure Blue, a low-c...   \n",
       "18  The acquisition seeks to use Watson for weathe...   \n",
       "19  In 1956, the company demonstrated the first pr...   \n",
       "\n",
       "                                            answer    predicted_answer  \n",
       "0                                   june 16 , 1911       June 16, 1911  \n",
       "1                                              5 %                  5%  \n",
       "2                                             1946                1946  \n",
       "3                                             spss              Kenexa  \n",
       "4                           universal product code                      \n",
       "5                                   second largest              second  \n",
       "6                                    4,100 gallons                 six  \n",
       "7                                             1924  The following year  \n",
       "8                                            linux                      \n",
       "9                                  mozilla firefox                      \n",
       "10                               project big green        A year later  \n",
       "11                                  developerworks                      \n",
       "12                                            1984                1984  \n",
       "13  computing-tabulating-recording company ( ctr )       Thomas Watson  \n",
       "14                                        endicott                1956  \n",
       "15                              sexual orientation                1961  \n",
       "16                                           think                      \n",
       "17                                            2006        A year later  \n",
       "18                                          watson                      \n",
       "19                                thomas j. watson    Arthur L. Samuel  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_devel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testing Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_result=pd.DataFrame(columns=['id','answer'])\n",
    "df_testing=pd.read_json('project_files/testing.json')\n",
    "df_testing=df_testing.iloc[0:10]\n",
    "NER_dict={}\n",
    "for index, row in df_testing.iterrows():\n",
    "    question=row['question']\n",
    "    docid=row['docid']\n",
    "    ida=row['id']\n",
    "    \n",
    "    #print('Question: ',question)\n",
    "    #print('Expected Answer:',expected_answer)\n",
    "    #print('Docid:',docid)\n",
    "    question_keywords=get_keyword(question)\n",
    "    \n",
    "    # get the most relevant documents for the question\n",
    "    results = query_vsm(question_keywords, vsm_inverted_index_all[docid])\n",
    "    documents_ranked=results.most_common(10) \n",
    "    #print('Top 10 paragraphs: ',documents_ranked)\n",
    "    q_bow=get_question_bow(question)\n",
    "    x = vectorizer.transform(q_bow)\n",
    "    answer_type=model.predict(x)\n",
    "    #print('Predicted answer type: ',answer_type)\n",
    "    \n",
    "    candidate_passages={}\n",
    "    list_of_passages=[]\n",
    "    answer=''\n",
    "    \n",
    "    if len(documents_ranked)>0:\n",
    "        for document in documents_ranked:\n",
    "            # perform a paragraph segmentation\n",
    "            paragraph=df_docs.iloc[docid]['text'][document[0]]\n",
    "            passages = tokenizer.tokenize(paragraph)\n",
    "            \n",
    "            for i in range(len(passages)):\n",
    "                list_of_passages.append(passages[i])\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "        ## PARAMETERS TO GET FROM TESTING DATASET AND USE A MODEL TO GET THE ANSWER PASSAGE CANDIDATES. \n",
    "        #question= df_training.loc[(df_training[\"docid\"] == docid_query) & (df_training[\"answer_paragraph\"] ==document[0] ),\"question\"][0]\n",
    "        #answer_type=df_training.loc[(df_training[\"docid\"] == docid_query) & (df_training[\"answer_paragraph\"] ==document[0] ),\"answer_type\"][0]\n",
    "        #print(question)\n",
    "        #print(answer_type) \n",
    "        #print(sorted(get_keyword(question)))\n",
    "        ###\n",
    "\n",
    "        ## FOR NOW USING KEYWORDS AND GET JUST ONE DEFINITE ANSWER PASSAGE CANDIDATE\n",
    "        indexPassage=0\n",
    "        score=0\n",
    "        for indexPassage in range(len(list_of_passages)):\n",
    "            NER_passage=get_Name_Entity_Sentence(list_of_passages[indexPassage])\n",
    "            common_keywords=get_number_of_common_kewyords(get_keyword(question),get_keyword(list_of_passages[indexPassage]))\n",
    "            similarity=nlp(question).similarity(nlp(list_of_passages[indexPassage]))\n",
    "            score=common_keywords+similarity\n",
    "            \n",
    "            for entity in NER_passage:\n",
    "                if (entity[1]==answer_type):\n",
    "                    score+=1\n",
    "                    break\n",
    "                \n",
    "            candidate_passages[indexPassage]=score\n",
    "\n",
    "        \n",
    "        if len(candidate_passages)>0:\n",
    "            best_candidate_passage=list_of_passages[max(candidate_passages, key=candidate_passages.get)]\n",
    "        else:\n",
    "            if len(list_of_passages)>0:\n",
    "                best_candidate_passage=list_of_passages[0]\n",
    "        #print(\"Candidate Passage Answer:\")\n",
    "        #print(best_candidate_passage)\n",
    "        \n",
    "        \n",
    "       \n",
    "        NER_answer_passage=get_Name_Entity_Sentence(best_candidate_passage)\n",
    "        for entity in NER_answer_passage:\n",
    "                if (entity[1]==answer_type):\n",
    "                    answer=entity[0]\n",
    "    \n",
    "    #print('Predicted answer:',answer)\n",
    "    print(ida)\n",
    "    \n",
    "    df_result.loc[len(df_result)]=[ida,answer]\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('prediction/output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subsample(x,y,subsample_size=1.0):\n",
    "    \n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            np.random.shuffle(this_xs)\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = np.concatenate(xs)\n",
    "    ys = np.concatenate(ys)\n",
    "\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df_devel=pd.read_json('project_files/devel.json')\n",
    "\n",
    "    \n",
    "def get_answer_rank_features(dataset):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for index, row in dataset.iterrows():\n",
    "        question=row['question']\n",
    "        raw_answer=row['text']\n",
    "\n",
    "        paragraph=df_docs.iloc[row['docid']]['text'][row['answer_paragraph']]\n",
    "        \n",
    "        #answer_found,dict_answer_sentence_ner,common_entities=get_answer_features(paragraph,raw_answer,row['NE_text'],row['NE_paragraph'])\n",
    "\n",
    "        # number of named entities in the passage\n",
    "        num_entities=len(common_entities)\n",
    "\n",
    "        # number of question keywords in the passage\n",
    "        question_keywords=get_keyword(question)\n",
    "        answer_passage_keywords=get_keyword(answer_found)\n",
    "        qk_passage=[]\n",
    "        for qk in question_keywords:\n",
    "            if qk in answer_passage_keywords:\n",
    "                qk_passage.append(qk)\n",
    "        num_qkp=len(qk_passage)   \n",
    "\n",
    "        # longest exact sequence of keywords\n",
    "        longest_exact_sequence=0\n",
    "\n",
    "        for i in range(len(question_keywords)):\n",
    "            if i < len(answer_passage_keywords):\n",
    "                if question_keywords[i] in answer_passage_keywords[i]:\n",
    "                    longest_exact_sequence+=1\n",
    "\n",
    "        # rank of the paragraph where the answer sentence was extracted\n",
    "        results = query_vsm(question_keywords, vsm_inverted_index_all[row['docid']])\n",
    "        documents_ranked=results.most_common(10) \n",
    "        rank_of_paragraph=0\n",
    "        for document in documents_ranked:\n",
    "            if (document[0]==row['answer_paragraph']):\n",
    "                break\n",
    "            else:\n",
    "                rank_of_paragraph+=1\n",
    "\n",
    "        #print('Question:',question)\n",
    "        #print('answer:',answer_found)\n",
    "\n",
    "        #print (num_entities,num_qkp,longest_exact_sequence,rank_of_paragraph)\n",
    "\n",
    "        tokenized_sentence = nltk.sent_tokenize(paragraph)\n",
    "        for sentence in tokenized_sentence:\n",
    "            X.append([num_entities,num_qkp,longest_exact_sequence,rank_of_paragraph])\n",
    "            #print(sentence)\n",
    "            if (sentence==answer_found):\n",
    "                Y.append(1)\n",
    "            else:\n",
    "                Y.append(0)\n",
    "\n",
    "        #print(Y_train)\n",
    "    \n",
    "    return X,Y\n",
    "\n",
    "\n",
    "    \n",
    "def get_answer_rank_features_devel(dataset):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for index, row in dataset.iterrows():\n",
    "        question=row['question']\n",
    "        raw_answer=row['text']\n",
    "        print(index)\n",
    "        paragraph=df_docs.iloc[row['docid']]['text'][row['answer_paragraph']]\n",
    "        \n",
    "        NE_answer=get_Name_Entity_Sentence(raw_answer)\n",
    "        NE_paragraph=get_Name_Entity_paragraph(paragraph)\n",
    "        #print(NE_answer)\n",
    "        answer_found,dict_answer_sentence_ner,common_entities=get_answer_features(paragraph,raw_answer,NE_answer,NE_paragraph)\n",
    "\n",
    "        # number of named entities in the passage\n",
    "        num_entities=len(common_entities)\n",
    "\n",
    "        # number of question keywords in the passage\n",
    "        question_keywords=get_keyword(question)\n",
    "        answer_passage_keywords=get_keyword(answer_found)\n",
    "        qk_passage=[]\n",
    "        for qk in question_keywords:\n",
    "            if qk in answer_passage_keywords:\n",
    "                qk_passage.append(qk)\n",
    "        num_qkp=len(qk_passage)   \n",
    "\n",
    "        # longest exact sequence of keywords\n",
    "        longest_exact_sequence=0\n",
    "\n",
    "        for i in range(len(question_keywords)):\n",
    "            if i < len(answer_passage_keywords):\n",
    "                if question_keywords[i] in answer_passage_keywords[i]:\n",
    "                    longest_exact_sequence+=1\n",
    "\n",
    "        # rank of the paragraph where the answer sentence was extracted\n",
    "        results = query_vsm(question_keywords, vsm_inverted_index_all[row['docid']])\n",
    "        documents_ranked=results.most_common(10) \n",
    "        rank_of_paragraph=0\n",
    "        for document in documents_ranked:\n",
    "            if (document[0]==row['answer_paragraph']):\n",
    "                break\n",
    "            else:\n",
    "                rank_of_paragraph+=1\n",
    "\n",
    "        #print('Question:',question)\n",
    "        #print('answer:',answer_found)\n",
    "\n",
    "        #print (num_entities,num_qkp,longest_exact_sequence,rank_of_paragraph)\n",
    "\n",
    "        tokenized_sentence = nltk.sent_tokenize(paragraph)\n",
    "        for sentence in tokenized_sentence:\n",
    "            \n",
    "            X.append([num_entities,num_qkp,longest_exact_sequence,rank_of_paragraph])\n",
    "            if (answer_found in sentence):\n",
    "                Y.append(1)\n",
    "            else:\n",
    "                Y.append(0)\n",
    "\n",
    "        #print(Y_train)\n",
    "        \n",
    "    return X,Y    \n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "\n",
    "X_train,Y_train=get_answer_rank_features(df_training)\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, stratify=Y_train, test_size=0.2)\n",
    "\n",
    "\n",
    "#print(X_train)\n",
    "#print(Y_train)\n",
    "LogReg.fit(X_train, Y_train)\n",
    "print('done training')\n",
    "X,Y=get_answer_rank_features_devel(df_devel)\n",
    "\n",
    "\n",
    "y_predicted_class = LogReg.predict(X)\n",
    "\n",
    "\n",
    "classifications=Y\n",
    "predictions=y_predicted_class\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print(accuracy_score(classifications,predictions))\n",
    "print(classification_report(classifications,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5396"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_passage_features(passage,question,answer_type):\n",
    "    # number of named entities in the passage\n",
    "        num_entities=len(common_entities)\n",
    "\n",
    "        # number of question keywords in the passage\n",
    "        question_keywords=get_keyword(question)\n",
    "        answer_passage_keywords=get_keyword(answer_found)\n",
    "        qk_passage=[]\n",
    "        for qk in question_keywords:\n",
    "            if qk in answer_passage_keywords:\n",
    "                qk_passage.append(qk)\n",
    "        num_qkp=len(qk_passage)   \n",
    "\n",
    "        # longest exact sequence of keywords\n",
    "        longest_exact_sequence=0\n",
    "\n",
    "        for i in range(len(question_keywords)):\n",
    "            if i < len(answer_passage_keywords):\n",
    "                if question_keywords[i] in answer_passage_keywords[i]:\n",
    "                    longest_exact_sequence+=1\n",
    "\n",
    "        # rank of the paragraph where the answer sentence was extracted\n",
    "        results = query_vsm(question_keywords, vsm_inverted_index_all[row['docid']])\n",
    "        documents_ranked=results.most_common(10) \n",
    "        rank_of_paragraph=0\n",
    "        for document in documents_ranked:\n",
    "            if (document[0]==row['answer_paragraph']):\n",
    "                break\n",
    "            else:\n",
    "                rank_of_paragraph+=1\n",
    "\n",
    "        return num_entities,num_qkp,longest_exact_sequence,rank_of_paragraph]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_paragraph</th>\n",
       "      <th>docid</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>On what date did the companies that became the Computing-Tabulating-Recording Company get consolidated?</td>\n",
       "      <td>june 16 , 1911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>380</td>\n",
       "      <td>What percentage of its desktop PCs does IBM plan to install Open Client on to?</td>\n",
       "      <td>5 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>380</td>\n",
       "      <td>What year did IBM hire its first black salesman?</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>380</td>\n",
       "      <td>IBM made an acquisition in 2009, name it.</td>\n",
       "      <td>spss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>380</td>\n",
       "      <td>This IBM invention is known by the acronym UPC, what is the full name?</td>\n",
       "      <td>universal product code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_paragraph  docid  \\\n",
       "0  5                 380     \n",
       "1  22                380     \n",
       "2  16                380     \n",
       "3  4                 380     \n",
       "4  2                 380     \n",
       "\n",
       "                                                                                                  question  \\\n",
       "0  On what date did the companies that became the Computing-Tabulating-Recording Company get consolidated?   \n",
       "1  What percentage of its desktop PCs does IBM plan to install Open Client on to?                            \n",
       "2  What year did IBM hire its first black salesman?                                                          \n",
       "3  IBM made an acquisition in 2009, name it.                                                                 \n",
       "4  This IBM invention is known by the acronym UPC, what is the full name?                                    \n",
       "\n",
       "                     text  \n",
       "0  june 16 , 1911          \n",
       "1  5 %                     \n",
       "2  1946                    \n",
       "3  spss                    \n",
       "4  universal product code  "
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "a={'a':1,'b':2,'c':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-427-6a1284577a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_paragraph</th>\n",
       "      <th>docid</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "      <th>NE_question</th>\n",
       "      <th>NE_text</th>\n",
       "      <th>NE_paragraph</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>keywords_question</th>\n",
       "      <th>question_type</th>\n",
       "      <th>POS_questions</th>\n",
       "      <th>answer_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>A kilogram could be definined as having a Planck constant of what value?</td>\n",
       "      <td>6966662606895999999♠6.62606896×10−34 j⋅s</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(6966662606895999999 ♠ 6.62606896, NUMBER), (10 − 34, NUMBER)]</td>\n",
       "      <td>[[(general, TITLE), (2011, DATE)], [], [(one, NUMBER)], [(7050135639273999999 ♠ 135639274 ×, NUMBER), (1042, DATE), (6966662606895999999 ♠ 6.62606896, NUMBER), (10 − 34, NUMBER), (⋅, NUMBER)]]</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>[kilogram, definined, planck, constant, value]</td>\n",
       "      <td>what</td>\n",
       "      <td>[NN, VBN, NNP, NN, NN]</td>\n",
       "      <td>Possible new definitions include \"the mass of a body at rest whose equivalent energy equals the energy of photons whose frequencies sum to 7050135639273999999♠135639274×1042 Hz\", or simply \"the kilogram is defined so that the Planck constant equals 6966662606895999999♠6.62606896×10−34 J⋅s\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the shape of the object that establishes the base unit of the kilogram?</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[], [], [(1889, DATE), (paris, CITY)], [(1889, DATE), (1, NUMBER), (one, NUMBER), (million, NUMBER)], [(one, NUMBER), (current, DATE), (planck, LOCATION)]]</td>\n",
       "      <td>None</td>\n",
       "      <td>[shape, object, establish, base, unit, kilogram]</td>\n",
       "      <td>what</td>\n",
       "      <td>[NN, NN, VBZ, JJ, NN, NN]</td>\n",
       "      <td>The most urgent unit on the list for redefinition is the kilogram, whose value has been fixed for all science (since 1889) by the mass of a small cylinder of platinum–iridium alloy kept in a vault just outside Paris.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>What example is given as another paired relationship of uncertainly related to standard deviation?</td>\n",
       "      <td>time vs. energy</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[], [], [(one, NUMBER)], [(fourier, LOCATION)]]</td>\n",
       "      <td>None</td>\n",
       "      <td>[example, give, pair, relationship, relate, standard, deviation]</td>\n",
       "      <td>what</td>\n",
       "      <td>[NN, VBN, JJ, NN, VBN, JJ, NN]</td>\n",
       "      <td>One example is time vs. energy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>What does the Planck Constant refer to?</td>\n",
       "      <td>quantum of action</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[], [(planck, PERSON)], [(now, DATE)], [], []]</td>\n",
       "      <td>None</td>\n",
       "      <td>[doe, planck, constant, refer]</td>\n",
       "      <td>what</td>\n",
       "      <td>[VBZ, NNP, NNP, NN]</td>\n",
       "      <td>Instead, it must be some multiple of a very small quantity, the \"quantum of action\", now called the Planck constant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>When was the first quantized model of the atom introduced?</td>\n",
       "      <td>1913</td>\n",
       "      <td>[(first, ORDINAL), (model, TITLE)]</td>\n",
       "      <td>[(1913, DATE)]</td>\n",
       "      <td>[[(niels bohr, PERSON), (first, ORDINAL), (model, TITLE), (1913, DATE), (rutherford, PERSON), (model, TITLE)], [], [], [(bohr, PERSON), (planck, PERSON), (bohr, PERSON)]]</td>\n",
       "      <td>DATE</td>\n",
       "      <td>[wa, first, quantize, model, atom, introduce]</td>\n",
       "      <td>when</td>\n",
       "      <td>[VBD, JJ, JJ, NN, NN, VBD]</td>\n",
       "      <td>Niels Bohr introduced the first quantized model of the atom in 1913, in an attempt to overcome a major shortcoming of Rutherford's classical model.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_paragraph  docid  \\\n",
       "0  23                0       \n",
       "1  22                0       \n",
       "2  12                0       \n",
       "3  1                 0       \n",
       "4  10                0       \n",
       "\n",
       "                                                                                             question  \\\n",
       "0  A kilogram could be definined as having a Planck constant of what value?                             \n",
       "1  What is the shape of the object that establishes the base unit of the kilogram?                      \n",
       "2  What example is given as another paired relationship of uncertainly related to standard deviation?   \n",
       "3  What does the Planck Constant refer to?                                                              \n",
       "4  When was the first quantized model of the atom introduced?                                           \n",
       "\n",
       "                                       text  \\\n",
       "0  6966662606895999999♠6.62606896×10−34 j⋅s   \n",
       "1  cylinder                                   \n",
       "2  time vs. energy                            \n",
       "3  quantum of action                          \n",
       "4  1913                                       \n",
       "\n",
       "                          NE_question  \\\n",
       "0  []                                   \n",
       "1  []                                   \n",
       "2  []                                   \n",
       "3  []                                   \n",
       "4  [(first, ORDINAL), (model, TITLE)]   \n",
       "\n",
       "                                                           NE_text  \\\n",
       "0  [(6966662606895999999 ♠ 6.62606896, NUMBER), (10 − 34, NUMBER)]   \n",
       "1  []                                                                \n",
       "2  []                                                                \n",
       "3  []                                                                \n",
       "4  [(1913, DATE)]                                                    \n",
       "\n",
       "                                                                                                                                                                                       NE_paragraph  \\\n",
       "0  [[(general, TITLE), (2011, DATE)], [], [(one, NUMBER)], [(7050135639273999999 ♠ 135639274 ×, NUMBER), (1042, DATE), (6966662606895999999 ♠ 6.62606896, NUMBER), (10 − 34, NUMBER), (⋅, NUMBER)]]   \n",
       "1  [[], [], [(1889, DATE), (paris, CITY)], [(1889, DATE), (1, NUMBER), (one, NUMBER), (million, NUMBER)], [(one, NUMBER), (current, DATE), (planck, LOCATION)]]                                       \n",
       "2  [[], [], [(one, NUMBER)], [(fourier, LOCATION)]]                                                                                                                                                   \n",
       "3  [[], [(planck, PERSON)], [(now, DATE)], [], []]                                                                                                                                                    \n",
       "4  [[(niels bohr, PERSON), (first, ORDINAL), (model, TITLE), (1913, DATE), (rutherford, PERSON), (model, TITLE)], [], [], [(bohr, PERSON), (planck, PERSON), (bohr, PERSON)]]                         \n",
       "\n",
       "  answer_type  \\\n",
       "0  NUMBER       \n",
       "1  None         \n",
       "2  None         \n",
       "3  None         \n",
       "4  DATE         \n",
       "\n",
       "                                                  keywords_question  \\\n",
       "0  [kilogram, definined, planck, constant, value]                     \n",
       "1  [shape, object, establish, base, unit, kilogram]                   \n",
       "2  [example, give, pair, relationship, relate, standard, deviation]   \n",
       "3  [doe, planck, constant, refer]                                     \n",
       "4  [wa, first, quantize, model, atom, introduce]                      \n",
       "\n",
       "  question_type                   POS_questions  \\\n",
       "0  what          [NN, VBN, NNP, NN, NN]           \n",
       "1  what          [NN, NN, VBZ, JJ, NN, NN]        \n",
       "2  what          [NN, VBN, JJ, NN, VBN, JJ, NN]   \n",
       "3  what          [VBZ, NNP, NNP, NN]              \n",
       "4  when          [VBD, JJ, JJ, NN, NN, VBD]       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                          answer_found  \n",
       "0  Possible new definitions include \"the mass of a body at rest whose equivalent energy equals the energy of photons whose frequencies sum to 7050135639273999999♠135639274×1042 Hz\", or simply \"the kilogram is defined so that the Planck constant equals 6966662606895999999♠6.62606896×10−34 J⋅s\".  \n",
       "1  The most urgent unit on the list for redefinition is the kilogram, whose value has been fixed for all science (since 1889) by the mass of a small cylinder of platinum–iridium alloy kept in a vault just outside Paris.                                                                             \n",
       "2  One example is time vs. energy.                                                                                                                                                                                                                                                                      \n",
       "3  Instead, it must be some multiple of a very small quantity, the \"quantum of action\", now called the Planck constant.                                                                                                                                                                                 \n",
       "4  Niels Bohr introduced the first quantized model of the atom in 1913, in an attempt to overcome a major shortcoming of Rutherford's classical model.                                                                                                                                                  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2743"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_training[df_training.answer_found=='UNKNOWN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_paragraph     19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "docid                28                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "question             What percent of Oklahomans speak only English at home, as of 2000?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "text                 92.6 %                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "NE_question          [(oklahomans, MISC), (english, NATIONALITY), (2000, DATE)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "NE_text              [(92.6 %, PERCENT)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "NE_paragraph         [[(english, NATIONALITY), (oklahoma, STATE_OR_PROVINCE), (2010, DATE)], [(north, MISC), (american english, NATIONALITY), (oklahoma, STATE_OR_PROVINCE), (english, NATIONALITY), (north, LOCATION), (midland, CITY), (south, LOCATION), (midland, CITY), (southern, MISC)], [(2000, DATE), (2,977,187, NUMBER), (oklahomans, MISC), (92.6 %, PERCENT), (five years, DURATION), (english, NATIONALITY), (95 %, PERCENT), (1990, DATE)], [(238,732, NUMBER), (oklahoma, STATE_OR_PROVINCE), (english, NATIONALITY), (2000, DATE), (7.4 %, PERCENT)], [(spanish, NATIONALITY), (second, ORDINAL), (141,060, NUMBER), (2000, DATE)], [(22,000, NUMBER), (oklahoma, STATE_OR_PROVINCE)], [(cherokee, MISC), (cherokee nation, ORGANIZATION), (united keetoowah band of cherokee indians, ORGANIZATION)]]\n",
       "answer_type          PERCENT                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "keywords_question    [percent, oklahoman, speak, english, home, 2000]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "question_type        what                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "POS_questions        [NN, NNP, VBP, NNP, NN, CD]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "answer_found         UNKNOWN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "Name: 3105, dtype: object"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.iloc[3105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "a='The winner of the 2014 Nobel Prize in Literature, Patrick Modiano–who lives in Paris–, based most of his literary work on the depiction of the city during World War II and the 1960s-1970s.'\n",
    "\n",
    "if 'patrick modiano' in a.lower():\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
