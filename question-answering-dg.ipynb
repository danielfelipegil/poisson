{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0. Exploratory analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df_training=pd.read_json('project_files/training.json', encoding = 'utf8')\n",
    "df_devel=pd.read_json('project_files/devel.json')\n",
    "df_docs=pd.read_json('project_files/documents.json')\n",
    "df_testing=pd.read_json('project_files/testing.json')\n",
    "\n",
    "df_training=pd.read_pickle('project_files/df_training.pkl')\n",
    "df_training=df_training.iloc[0:2000]\n",
    "#df_docs=df_docs.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_paragraph</th>\n",
       "      <th>docid</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "      <th>NE_question</th>\n",
       "      <th>NE_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>A kilogram could be definined as having a Planck constant of what value?</td>\n",
       "      <td>6966662606895999999♠6.62606896×10−34 j⋅s</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(6966662606895999999 ♠ 6.62606896, NUMBER), (10 − 34, NUMBER)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the shape of the object that establishes the base unit of the kilogram?</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>What example is given as another paired relationship of uncertainly related to standard deviation?</td>\n",
       "      <td>time vs. energy</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>What does the Planck Constant refer to?</td>\n",
       "      <td>quantum of action</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>When was the first quantized model of the atom introduced?</td>\n",
       "      <td>1913</td>\n",
       "      <td>[(first, ORDINAL), (model, TITLE)]</td>\n",
       "      <td>[(1913, DATE)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_paragraph  docid  \\\n",
       "0  23                0       \n",
       "1  22                0       \n",
       "2  12                0       \n",
       "3  1                 0       \n",
       "4  10                0       \n",
       "\n",
       "                                                                                             question  \\\n",
       "0  A kilogram could be definined as having a Planck constant of what value?                             \n",
       "1  What is the shape of the object that establishes the base unit of the kilogram?                      \n",
       "2  What example is given as another paired relationship of uncertainly related to standard deviation?   \n",
       "3  What does the Planck Constant refer to?                                                              \n",
       "4  When was the first quantized model of the atom introduced?                                           \n",
       "\n",
       "                                       text  \\\n",
       "0  6966662606895999999♠6.62606896×10−34 j⋅s   \n",
       "1  cylinder                                   \n",
       "2  time vs. energy                            \n",
       "3  quantum of action                          \n",
       "4  1913                                       \n",
       "\n",
       "                          NE_question  \\\n",
       "0  []                                   \n",
       "1  []                                   \n",
       "2  []                                   \n",
       "3  []                                   \n",
       "4  [(first, ORDINAL), (model, TITLE)]   \n",
       "\n",
       "                                                           NE_text  \n",
       "0  [(6966662606895999999 ♠ 6.62606896, NUMBER), (10 − 34, NUMBER)]  \n",
       "1  []                                                               \n",
       "2  []                                                               \n",
       "3  []                                                               \n",
       "4  [(1913, DATE)]                                                   "
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Question processing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find Keywords\n",
    "2. Answer types - Using answer type taxonomy\n",
    "3. Query formulation -> Keywords\n",
    "4. Go to each document and check the frequency distribution of words and pick the document if one of the query words are present in document. Create a rank with that score\n",
    "5. Find the paragraphs -> Discard irrelevant paragraphs. Use NE,Keywords, longest exact keywords. Put same weight for now and calculate the score of paragraphs. Rank each of the paragraphs in the document. We have to use the original answer and match the answer type\n",
    "6. Find candidate answers -> Use supervised ML method\n",
    "7. Merge candidate answers -> Use NER\n",
    "8. Pick the best answer -> Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring Stanford CoreNLP . Link -> https://blog.manash.me/configuring-stanford-parser-and-stanford-ner-tagger-with-nltk-in-python-on-windows-f685483c374a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.tag.stanford import CoreNLPNERTagger\n",
    "from itertools import groupby\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) \n",
    "stemmer = nltk.stem.PorterStemmer() \n",
    "\n",
    "def get_Name_Entity_NLTK(data):\n",
    "    results=[]\n",
    "    for sentence in data:\n",
    "        ne_chunked_sents = ne_chunk(pos_tag(word_tokenize(sentence)))\n",
    "        result = []\n",
    "\n",
    "        for tagged_tree in ne_chunked_sents:\n",
    "\n",
    "            if hasattr(tagged_tree, 'label'):\n",
    "                entity_name = ' '.join(c[0] for c in tagged_tree.leaves()) #\n",
    "                entity_type = tagged_tree.label() # get NE category\n",
    "                result.append((entity_name, entity_type))\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_Name_Entity_Sentence(sentence):\n",
    "    st = CoreNLPNERTagger(url='http://localhost:9000')\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    classified_text = st.tag(tokenized_text)\n",
    "    result = {}\n",
    "    \n",
    "    for res in classified_text:\n",
    "        if len(res) > 0:\n",
    "            for tag, chunk in groupby(classified_text, lambda x:x[1]):\n",
    "               if tag != \"O\":\n",
    "                    word = \" \".join(w for w, t in chunk)\n",
    "                    result[word.lower()] = tag\n",
    "    \n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_Name_Entity_paragraph(paragraph):\n",
    "    result = []\n",
    "    tokenized_sentence = nltk.sent_tokenize(paragraph)\n",
    "    for sentence in tokenized_sentence:\n",
    "        result.append(get_Name_Entity_Sentence(sentence))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_Name_Entity_StanfordCoreNLP(data):\n",
    "    st = CoreNLPNERTagger(url='http://localhost:9000')\n",
    "    results=[]\n",
    "    for sentence in data:\n",
    "        tokenized_text = nltk.word_tokenize(sentence)\n",
    "        classified_text = st.tag(tokenized_text)\n",
    "        result = []\n",
    "        for tag, chunk in groupby(classified_text, lambda x:x[1]):\n",
    "            if tag != \"O\":\n",
    "                word = \" \".join(w for w, t in chunk)\n",
    "                result.append((word.lower(),tag))\n",
    "       \n",
    "        results.append(result)\n",
    "        \n",
    "    return results\n",
    "\n",
    "def addNameEntity(df,feature,func):\n",
    "    if 'NE'+\"_\"+feature in df:\n",
    "        df = df.drop('NE'+\"_\"+feature, axis=1)\n",
    "    df[\"NE\"+\"_\"+feature] = func(df[feature])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_training = addNameEntity(df_training,\"question\",get_Name_Entity_StanfordCoreNLP)\n",
    "#df_training = addNameEntity(df_training,\"text\",get_Name_Entity_StanfordCoreNLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "POS = set([\"NN\",\"NNS\",\"NNP\",\"NNPS\",\"CD\",\"JJ\",\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\"]) \n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) \n",
    "stemmer = nltk.stem.PorterStemmer() \n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,wn.NOUN)\n",
    "    if (lemma == word):\n",
    "        lemma = lemmatizer.lemmatize(word,wn.VERB)\n",
    "        \n",
    "    return lemma\n",
    "\n",
    "def get_keyword(data):\n",
    "    result = []\n",
    "    sentence=data\n",
    "    tokenized_text = tokenizer.tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokenized_text)\n",
    "    for text,pos in tagged:\n",
    "        text = lemmatize(text.lower())\n",
    "        if text not in stopwords:\n",
    "            if pos in POS:\n",
    "                result.append(text)\n",
    "                \n",
    "    return result\n",
    "\n",
    "def get_keyword_paragraph(data):\n",
    "    results=[]\n",
    "    tokenized_sentence = nltk.sent_tokenize(data)\n",
    "    for sentence in tokenized_sentence:\n",
    "        result = get_keyword(sentence)\n",
    "        results.append(result)\n",
    "        \n",
    "    return results\n",
    "\n",
    "def get_keyword_all(data):\n",
    "    results=[]\n",
    "    for sentence in data:\n",
    "        result = get_keyword(sentence)\n",
    "        results.append(result)\n",
    "        \n",
    "    return results\n",
    "\n",
    "def add_keywords(df,feature):\n",
    "    if 'keywords'+\"_\"+feature in df:\n",
    "        df = df.drop('keywords'+\"_\"+feature, axis=1)\n",
    "    df['keywords'+\"_\"+feature]=get_keyword_all(df[feature])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_training = add_keywords(df_training,'question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train a classifier</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_answer_features(passage,answer):\n",
    "    \n",
    "    sents_passage = nltk.sent_tokenize(passage)\n",
    "    answer_sentence_ner={'UNKNOWN':'UNKNOWN'}\n",
    "    answer_found='UNKNOWN'\n",
    "    answer_sentence_keywords=[]\n",
    "    common_entities=tuple()\n",
    "    for sentence in sents_passage:\n",
    "        if answer.lower() in sentence.lower():\n",
    "            answer_found=sentence\n",
    "            dict_answer_sentence_ner=get_Name_Entity_Sentence(sentence)\n",
    "            dict_answer_ner=get_Name_Entity_Sentence(answer)\n",
    "            common_entities = set(dict_answer_sentence_ner.items()) & set(dict_answer_ner.items())\n",
    "            break\n",
    "    \n",
    "    return answer_found,common_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# get the training data set as we need it\n",
    "answer_type={}\n",
    "def prepare_training_data():\n",
    "    \n",
    "    df_training['answer_type']='UNKNOWN'\n",
    "    df_training['answer_found']='UNKNOWN'\n",
    "    df_training['common_entities']='UNKNOWN'\n",
    "    df_training['NE_passage']='UNKNOWN'\n",
    "    for index, row in df_training.iterrows():\n",
    "        question=row['question']\n",
    "        raw_answer=row['text']\n",
    "        \n",
    "        passage=df_docs.iloc[row['docid']]['text'][row['answer_paragraph']]\n",
    "        \n",
    "        answer_found,common_entities=get_answer_features(passage,raw_answer)\n",
    "        \n",
    "        if (len(common_entities)>0):\n",
    "            ans=list(common_entities)[0][1]\n",
    "            \n",
    "        else:\n",
    "            ans='UNKNOWN'\n",
    "            \n",
    "        df_training.at[index,'answer_type']=ans\n",
    "        df_training.at[index,'answer_found']=answer_found\n",
    "        df_training.at[index,'common_entities']=shared_items\n",
    "        \n",
    "        ###\n",
    "        df_training.at[index,'NE_passage']=get_Name_Entity_paragraph(passage)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df_training[['question','text','answer_found','NE_passage','answer_type','NE_text','NE_question','common_entities']][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW extraction for passages and questions\n",
    "\n",
    "\n",
    "def get_passages_bow(passages):\n",
    "    passage_bow={}\n",
    "    for passage in passages:\n",
    "        for token in nltk.word_tokenize(passage):\n",
    "            if token not in stopwords: \n",
    "                word=stemmer.stem(token.lower())\n",
    "                passage_bow[word] = passage_bow.get(word, 0) +  1\n",
    "    \n",
    "    return passage_bow\n",
    "\n",
    "def get_sentences_bow(sentences):\n",
    "    sentence_bow={}\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for token in nltk.word_tokenize(sentence):\n",
    "            if token not in stopwords:\n",
    "                word=stemmer.stem(token.lower())\n",
    "                sentence_bow[word] = sentence_bow.get(word, 0) +  1\n",
    "    \n",
    "    return sentence_bow\n",
    "\n",
    "\n",
    "def get_question_bow(question,keywords):\n",
    "    question_bow={}\n",
    "    for token in nltk.word_tokenize(question):\n",
    "        if token not in stopwords: \n",
    "            word=stemmer.stem(token.lower())\n",
    "            if word in keywords:\n",
    "                question_bow[word] = question_bow.get(word, 0) +  1\n",
    "                \n",
    "    return question_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_questions():\n",
    "    questions=[]\n",
    "    questions_not_found=[]\n",
    "    answers_not_found=[]\n",
    "    classes=[]\n",
    "    for index, row in df_training.iterrows():\n",
    "        if len(row['common_entities'])>0 and row['answer_type']!='UNKNOWN':\n",
    "            questions.append(row['question'])\n",
    "            classes.append(row['answer_type'])\n",
    "        else:\n",
    "            questions_not_found.append(row['question'])\n",
    "            answers_not_found.append(row['text'])\n",
    "            \n",
    "    return questions,classes,questions_not_found,answers_not_found\n",
    "        \n",
    "def get_feature_questions(questions, keywords):\n",
    "    qs = []\n",
    "    for question in questions:\n",
    "        q_bow = get_question_bow(question,keywords)\n",
    "        qs.append(q_bow)\n",
    "        \n",
    "    return qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "    \n",
    "# get the most common words from answer sentences (we can twek this for paragraph)\n",
    "answer_sentences_bow=get_sentences_bow(df_training['answer_found'])\n",
    "answer_keywords = set([word for word, count in answer_sentences_bow.items()])\n",
    "\n",
    "#filter questions with common entities\n",
    "questions,classes,questions_not_found,answers_not_found=filter_questions()\n",
    "\n",
    "\n",
    "qs=get_feature_questions(questions,answer_keywords)\n",
    "\n",
    "\n",
    "qs_training=qs\n",
    "qs_testing=get_feature_questions(questions_not_found,answer_keywords)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'base': 1,\n",
       "  'establish': 1,\n",
       "  'kilogram': 1,\n",
       "  'object': 1,\n",
       "  'shape': 1,\n",
       "  'unit': 1},\n",
       " {'anoth': 1,\n",
       "  'exampl': 1,\n",
       "  'given': 1,\n",
       "  'pair': 1,\n",
       "  'relat': 1,\n",
       "  'relationship': 1,\n",
       "  'standard': 1},\n",
       " {'constant': 1, 'planck': 1, 'refer': 1},\n",
       " {'black': 1, 'bodi': 1, 'first': 1, 'radiat': 1, 'scientist': 1, 'studi': 1},\n",
       " {'1926': 1,\n",
       "  'correct': 1,\n",
       "  'electron': 1,\n",
       "  'give': 1,\n",
       "  'help': 1,\n",
       "  'quantiz': 1,\n",
       "  'rule': 1},\n",
       " {'classic': 1, 'exist': 1, 'mechan': 1, 'requir': 1, 'statist': 1},\n",
       " {'classic': 1, 'exist': 1, 'mechan': 1, 'requir': 1, 'statist': 1},\n",
       " {'contain': 1,\n",
       "  'energi': 1,\n",
       "  'eye': 1,\n",
       "  'human': 1,\n",
       "  'light': 1,\n",
       "  'much': 1,\n",
       "  'sensit': 1},\n",
       " {'also': 1, 'frequenc': 1, 'known': 1, 'scienc': 1},\n",
       " {'effect': 1, 'first': 1, 'observ': 1, 'photoelectr': 1},\n",
       " {\"''\": 1,\n",
       "  ',': 1,\n",
       "  '``': 1,\n",
       "  'came': 1,\n",
       "  'catastroph': 1,\n",
       "  'term': 1,\n",
       "  'ultraviolet': 1},\n",
       " {'act': 1, 'photoelectron': 1, 'term': 1, 'time': 1, 'use': 1, 'virtual': 1},\n",
       " {'atom': 1, 'nuclei': 1, 'properti': 1, 'unit': 1},\n",
       " {'associ': 1, 'discov': 1, 'e': 1, 'energi': 1, 'quantum': 1, 'valu': 1},\n",
       " {'effect': 1, 'first': 1, 'observ': 1, 'photoelectr': 1},\n",
       " {'come': 1,\n",
       "  'electromagnet': 1,\n",
       "  'equilibrium': 1,\n",
       "  'field': 1,\n",
       "  'requir': 1,\n",
       "  'thermal': 1},\n",
       " {'1921': 1,\n",
       "  'effect': 1,\n",
       "  'nobel': 1,\n",
       "  'photoelectr': 1,\n",
       "  'prize': 1,\n",
       "  'receiv': 1,\n",
       "  'work': 1},\n",
       " {'accur': 1,\n",
       "  'assumpt': 1,\n",
       "  'black-bodi': 1,\n",
       "  'lead': 1,\n",
       "  'predict': 1,\n",
       "  'radiat': 1},\n",
       " {'amount': 1, 'describ': 1, 'element': 1, 'small': 1, 'term': 1},\n",
       " {',': 1,\n",
       "  'atom': 1,\n",
       "  'certain': 1,\n",
       "  'consid': 1,\n",
       "  'constant': 1,\n",
       "  'energi': 1,\n",
       "  'level': 1,\n",
       "  'planck': 1,\n",
       "  'regard': 1,\n",
       "  'valu': 1}]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_testing[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9453125\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   CAUSE_OF_DEATH       1.00      0.88      0.94        17\n",
      "             CITY       0.00      0.00      0.00         1\n",
      "          COUNTRY       0.90      0.95      0.92        37\n",
      "  CRIMINAL_CHARGE       1.00      1.00      1.00         1\n",
      "             DATE       0.92      0.99      0.96       216\n",
      "         DURATION       0.90      0.95      0.92        19\n",
      "         IDEOLOGY       1.00      0.67      0.80         3\n",
      "         LOCATION       1.00      1.00      1.00         1\n",
      "            MONEY       1.00      0.60      0.75         5\n",
      "      NATIONALITY       1.00      0.71      0.83        24\n",
      "           NUMBER       0.97      0.97      0.97       181\n",
      "          ORDINAL       1.00      0.86      0.92         7\n",
      "          PERCENT       1.00      1.00      1.00         9\n",
      "           PERSON       0.93      0.95      0.94        57\n",
      "         RELIGION       1.00      1.00      1.00        10\n",
      "              SET       1.00      0.67      0.80         3\n",
      "STATE_OR_PROVINCE       1.00      0.67      0.80         3\n",
      "            TITLE       0.95      0.89      0.92        46\n",
      "\n",
      "      avg / total       0.95      0.95      0.94       640\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielgil/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "if (len(qs)>0 and len(classes)>0):\n",
    "    # fit vectorizer\n",
    "    vectorizer = DictVectorizer()\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train_dtm = vectorizer.fit_transform(qs_training)\n",
    "    \n",
    "    X_test_dtm = vectorizer.transform(qs_testing[0:20])\n",
    "    \n",
    "    # tag the answers\n",
    "    # fit a logistic regression model to the data \n",
    "    # build classifier\n",
    "    model = MultinomialNB(2, False, None)\n",
    "\n",
    "    # train the model using X_train_dtm \n",
    "    model.fit(X_train_dtm, classes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_predicted_class = model.predict(X_train_dtm)\n",
    "    \n",
    "    #for i in range(20):\n",
    "     #   print(questions_not_found[i]),\n",
    "     #   print(answers_not_found[i]),\n",
    "     #   print(y_predicted_class[i])\n",
    "    \n",
    "    check_results(y_predicted_class,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def check_results(predictions, classifications):\n",
    "    print(\"Accuracy:\")\n",
    "    print(accuracy_score(classifications,predictions))\n",
    "    print(classification_report(classifications,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Candidate answering generation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Get a score for the passage to filter the most relevant passages</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## features relevant to this part\n",
    "# number of named entities of the right type in the passage\n",
    "# number of question keywords in the passage\n",
    "# the longest exact sequence of question keywords\n",
    "# rank of the document where the passage was extracted\n",
    "# proximity of the keywords from the original query\n",
    "# ngram overlap between the passage and the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will set up useful functions to extract term frequencies to build the vector space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) # wrap in a set() (see below)\n",
    "stemmer = nltk.stem.PorterStemmer() \n",
    "\n",
    "# get the terms for a passage\n",
    "def get_terms(passage):\n",
    "    terms = set()\n",
    "    for token in nltk.word_tokenize(passage):\n",
    "        if token not in stopwords: \n",
    "            terms.add(stemmer.stem(token.lower()))\n",
    "    return terms\n",
    "    \n",
    "# get document_term \n",
    "def get_document_term_passsages(ds_documents):\n",
    "    document_term={}\n",
    "    passageID=0\n",
    "    for index, row in ds_documents.iterrows():\n",
    "        # every row is a document\n",
    "        list_of_passages=row['text']\n",
    "        for passage in list_of_passages:\n",
    "            terms=get_terms(passage)\n",
    "            document_term[passageID]=terms\n",
    "            passageID+=1\n",
    "        \n",
    "    return document_term\n",
    "\n",
    "# get the term frequency\n",
    "def extract_term_freqs(doc):\n",
    "    tfs = Counter()\n",
    "    for token in doc:\n",
    "        if token not in stopwords: \n",
    "            tfs[stemmer.stem(token.lower())] += 1\n",
    "    return tfs\n",
    "        \n",
    "# compute idf\n",
    "def compute_doc_freqs(doc_term_freqs):\n",
    "    dfs = Counter()\n",
    "    for tfs in doc_term_freqs.values():\n",
    "        for term in tfs.keys():\n",
    "            dfs[term] += 1\n",
    "    return dfs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a document-term matrix\n",
    "docs=get_document_term_passsages(df_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector space model we need to define a score function\n",
    "# first I will use tf-idf\n",
    "doc_term_freqs = {}\n",
    "for docid, terms in docs.items():\n",
    "    term_freqs = extract_term_freqs(terms)\n",
    "    doc_term_freqs[docid] = term_freqs\n",
    "\n",
    "M = len(doc_term_freqs)\n",
    "\n",
    "doc_freqs = compute_doc_freqs(doc_term_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Improvement:</b> Use BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an inverted index for query processing. Inverted index will not change from query to query. Here we can improve how the weight is defined for the posting list tuple for each term (docid,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from WSTA_N16_information_retrieval\n",
    "vsm_inverted_index = defaultdict(list)\n",
    "for docid, term_freqs in doc_term_freqs.items():\n",
    "    N = sum(term_freqs.values())\n",
    "    length = 0\n",
    "    \n",
    "    # find tf*idf values and accumulate sum of squares \n",
    "    tfidf_values = []\n",
    "    for term, count in term_freqs.items():\n",
    "        tfidf = float(count) / N * log(M / float(doc_freqs[term]))\n",
    "        tfidf_values.append((term, tfidf))\n",
    "        length += tfidf ** 2\n",
    "\n",
    "    # normalise documents by length and insert into index\n",
    "    length = length ** 0.5\n",
    "    for term, tfidf in tfidf_values:\n",
    "        # note the inversion of the indexing, to be term -> (doc_id, score)\n",
    "        vsm_inverted_index[term].append([docid, tfidf / length])\n",
    "        \n",
    "# ensure posting lists are in sorted order (less important here cf above)\n",
    "for term, docids in vsm_inverted_index.items():\n",
    "    docids.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the VSM creating a score for each document (passage) and returning the top k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vsm(query, index, k=10):\n",
    "    accumulator = Counter()\n",
    "    for term in query:\n",
    "        postings = index[term]\n",
    "        for docid, weight in postings:\n",
    "            accumulator[docid] += weight\n",
    "    return accumulator.most_common(k)\n",
    "\n",
    "## end copied code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.680116589444509),\n",
       " (1, 0.30340274351915997),\n",
       " (6, 0.24364584220578492),\n",
       " (65, 0.17637606987370624),\n",
       " (105, 0.16152465265290256),\n",
       " (10, 0.14946948590599873),\n",
       " (3, 0.14114017042707586),\n",
       " (14, 0.13829184288746416),\n",
       " (11, 0.13227012047661246),\n",
       " (19, 0.10701743930986322)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = query_vsm([stemmer.stem(term.lower()) for term in \"First recognized in 1900 by Max Planck\".split()], vsm_inverted_index)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Candidate answering scoring</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Answer and confidence</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
